from Bio import SeqIO
from Bio.SeqRecord import SeqRecord
from Bio.SeqFeature import SeqFeature, FeatureLocation
import pandas as pd
from os.path import isfile, isdir
from os import remove, listdir
import subprocess
from celery_blast.settings import BLAST_PROJECT_DIR

'''extract_gene_cluster_by_one_sequence

    This function parses the genbank file and extracts all sequences that reside within the defined limits around
    the specified sequence. It then writes a new GenBank file that can be used for clinker to build synteny plots.
    The sequence parameter is the target sequence around which synteny is discovered. The limits paramater defines the 
    amount of upstream and downstream sequences to extract. The function returns a returncode: 0 success, 1 fail. 
    
    :param sequence
        :type str
    :param limits
        :type int
    :param gbfilepath
        :type str
    :param newfilename
        :type str
    :param project_id
        :type int
    
    :returns returncode
        :type int

'''
def extract_gene_cluster_by_one_sequence(sequence: str, limits: int, gbfilepath: str, newfilename: str, project_id:int)->int:
    try:
        filename = newfilename.split("/")[-1].split(".")[0]
        logfile = BLAST_PROJECT_DIR + str(project_id) + '/log/' + filename + '.log'
        with open(logfile, 'w') as log:
            try:
                log.write("INFO:START parsing genbank file\n")
                records = []
                for record in SeqIO.parse(gbfilepath, 'genbank'):
                    records.append(record)
                log.write("INFO:Records length is: {}\n".format(len(records)))
                record_counter = 0
                for gb in records:
                    parser_switch = 0
                    counter = 0
                    for feature in gb.features:
                        counter += 1

                        # there can be different annotations within an genbank file, this setup aims to also use
                        # custom genbank files generated by programs similar to prokka
                        if 'protein_id' in feature.qualifiers.keys():
                            if feature.qualifiers['protein_id'][0].split('.')[0] == sequence:
                                log.write("INFO:Found start sequence in record: {}\n".format(record_counter))
                                parser_switch = 1
                        elif 'locus_tag' in feature.qualifiers.keys():
                            if feature.qualifiers['locus_tag'][0].split('.')[0] == sequence:
                                log.write("INFO:Found start sequence in record: {}\n".format(record_counter))
                                parser_switch = 1

                        if parser_switch == 1:
                            log.write("INFO:DONE parsing\n")
                            break
                    if parser_switch == 1:
                        break
                    else:
                        record_counter += 1

                try:
                    log.write("INFO:Trying to extract features ... \n")
                    log.write("INFO:Setting up start and end features of the specified genbank record ... \n")
                    log.write("INFO:Length of record features: {}\n".format(len(records[record_counter].features)))
                    start = 0 if counter - limits < 0 else counter - limits
                    end = len(records[record_counter].features) if limits + counter > len(
                        records[record_counter].features) else limits + counter
                    gb = records[record_counter]
                    log.write("INFO:Selecting record number: {}, target sequence in feature: {}, slicing record features from: {} to {} ..\n".format(record_counter, counter, start, end))
                    locus_tags = []
                    relevant_features = []
                    id_to_location = {}
                    for feature in gb.features[start:end]:
                        if feature.type == 'gene' or feature.type == 'CDS':

                            if 'protein_id' in feature.qualifiers.keys():
                                if feature.qualifiers['protein_id'][0] not in locus_tags:
                                    locus_tags.append(feature.qualifiers['protein_id'][0])
                                    relevant_features.append(feature)
                                    id_to_location[feature.qualifiers['protein_id'][0]] = [feature.location]
                            else:
                                if 'locus_tag' in feature.qualifiers.keys():
                                    if feature.qualifiers['locus_tag'][0] not in locus_tags:
                                        locus_tags.append(feature.qualifiers['locus_tag'][0])
                                        relevant_features.append(feature)
                                        id_to_location[feature.qualifiers['locus_tag'][0]] = [feature.location]
                except Exception:
                    log.write("WARNING:{} does not reside in this genbank file, skipping this assembly\n".format(sequence))
                    return 0

                if len(locus_tags) <= 1:
                    log.write("WARNING:There are not enough sequences in the sliced GenBank file ...\n")
                    return 1

                log.write("INFO:Number of GENES in new GenBankFile: {}\n".format(len(locus_tags)))

                log.write("INFO:Extacting new sequence regions ...\n")
                qseq_location_dict = {}
                for index, qseq in enumerate(id_to_location.keys()):
                    if index == 0:
                        start = 1
                        value = id_to_location[qseq][0].end - id_to_location[qseq][0].start + 1
                        strand = id_to_location[qseq][0].strand
                        end = value

                        qseq_location_dict[qseq] = [start, end, strand]
                    else:
                        value = id_to_location[qseq][0].end - id_to_location[qseq][0].start
                        strand = id_to_location[qseq][0].strand
                        new_start = end + (id_to_location[qseq][0].start - id_to_location[locus_tags[index - 1]][0].end)
                        end = new_start + value

                        qseq_location_dict[qseq] = [new_start, end, strand]

                for feature in relevant_features:
                    if 'protein_id' in feature.qualifiers.keys():
                        if feature.qualifiers['protein_id'][0] in locus_tags:
                            locus_tag = feature.qualifiers['protein_id'][0]
                    elif 'locus_tag' in feature.qualifiers.keys():
                        if feature.qualifiers['locus_tag'][0] in locus_tags:
                            locus_tag = feature.qualifiers['locus_tag'][0]
                    location = FeatureLocation(qseq_location_dict[locus_tag][0], qseq_location_dict[locus_tag][1],
                                               qseq_location_dict[locus_tag][2])
                    feature.location = location


                new_sequence = gb.seq[id_to_location[locus_tags[0]][0].start - 1:id_to_location[locus_tags[-1]][0].end]

                log.write("INFO:DONE with the extraction ...\n")
                log.write("INFO:Writing new GenBank file ...\n")
                seq_record = SeqRecord(id=gb.id,
                                       name=gb.name,
                                       description=gb.description,
                                       annotations=gb.annotations,
                                       letter_annotations=gb.letter_annotations,
                                       seq=new_sequence)

                for feature in relevant_features:
                    seq_record.features.append(feature)

                with open(newfilename, "w") as gbfile:
                    SeqIO.write(seq_record, gbfile, 'genbank')
                log.write("DONE")
            except Exception as e:
                log.write("ERROR:Exception: {}".format(e))
                raise Exception(e)
        return 0
    except Exception as e:
        raise Exception(
            "[-] ERROR during extraction of gene-loci defined by {} protein id with Exception : {}".format(sequence, e))

'''extract_assembly_ftp_paths_from_reciprocal_result_entries

    This function extracts the specified assembly ftp paths for GenBank file downloading.
    The function returns a dictionary with sequence ids as key (those sequence ids are the respective RBHs) and 
    ftp_paths for the "_genomic.gbff.gz" file as values.
    
    :param database_table_path - project forward database 
        :type str
    :param result_table_path - reciprocal BLAST result table
        :type str
    :param: genome_assemblies - user specified genome assembly to download
        :type list
    
    :returns sequence_id_to_ftp_path
        :type dict
'''
def extract_assembly_ftp_paths_from_reciprocal_result_entries(database_table_path:str,result_data_path:str,genome_assemblies:list, project_id:int)->dict:
    try:
        logfile = BLAST_PROJECT_DIR + str(project_id) + '/log/' + 'genbank_ftp_path_extraction.log'
        with open(logfile, 'w') as log:
            try:
                log.write("INFO:Trying to extract assemblies from reciprocal result dataframe and database table\n")
                log.write("INFO:Number of assemblies to download: {}\n".format(len(genome_assemblies)))
                result_table = pd.read_csv(result_data_path, index_col=0)
                database_table = pd.read_csv(database_table_path, index_col=0)
                sequence_id_to_ftp_path = {}
                database_table = database_table.rename(columns={"taxid":"staxids"})
                log.write("INFO:merging database table with sliced result table\n")
                result_selection = result_table[result_table.sacc_transformed.isin(genome_assemblies)]
                database_table = database_table.merge(result_selection,on="staxids")
                database_table = database_table[['assembly_accession', 'staxids', 'organism_name', 'ftp_path', 'sacc_transformed']]
                # this will drop potential paralogous sequences
                # database_table = database_table.drop_duplicates(subset="ftp_path", keep="first")
                log.write("INFO:done merging result tables ...\n")
                log.write("INFO:building result dictionary for {} target sequences\n".format(len(database_table.sacc_transformed)))
                for seqid, ftp_path in zip(database_table.sacc_transformed, database_table.ftp_path):
                    genbank_path = '/'.join(ftp_path.split("/")[0:-1])
                    genbank_path += '/' + ftp_path.split("/")[-1].split("_protein.faa.gz")[0] + '_genomic.gbff.gz'
                    # there may be multiple assembly entries for some organisms,
                    # therefore download all assemblies and decide within the extract function which assembly is the right one
                    if seqid not in sequence_id_to_ftp_path.keys():
                        sequence_id_to_ftp_path[seqid] = [genbank_path]
                    else:
                        sequence_id_to_ftp_path[seqid].append(genbank_path)
            except Exception as e:
                log.write("ERROR:Exception {}".format(e))
                raise Exception(e)
            log.write("DONE")
        return sequence_id_to_ftp_path
    except Exception as e:
        raise Exception("[-] ERROR during extraction of genbank assembly ftp paths from database table with exception: {}".format(e))


'''download_genbank_files
    
    This function downloads genbank files specified in the sequence_id_to_ftp_path dictionary, which is derived by 
    executing the function extract_assembly_ftp_paths_from_reciprocal_result_entries. It iterates over the target sequences
    and downloads the genbank files, that are the values of this dictionary. It extract the *_genomic.gbff.gz file in the
    specified output_filepath directory. It returns a list of strings with paths of the downloaded genbank files.
    
    :param sequence_id_to_ftp_path - derived by extract_assembly_ftp_paths_from_reciprocal_result_entries
        :type dict
    :param output_filepath - output directory (e.g. blast_projects/2/clinker_synteny)
        :type str
        
    :returns downloaded_files
        :type list[str]
'''
def download_genbank_files(sequence_id_to_ftp_path: dict, output_filepath: str, project_id:int) -> list:
    try:
        logfile = BLAST_PROJECT_DIR + str(project_id) + '/log/' + "genbank_file_download.log"
        with open(logfile, 'w') as log:
            genbank_filelist = []
            try:
                for seqid in sequence_id_to_ftp_path.keys():
                    for ftp_path in sequence_id_to_ftp_path[seqid]:
                        genbank_filename = ftp_path.split('/')[-1].split(".gz")[0]
                        genbank_filename = output_filepath + '/' + genbank_filename
                        if (isfile(genbank_filename) == True):
                            log.write("INFO:GenBank file already exist, skipping download ...\n")
                            genbank_filelist.append(genbank_filename)
                        else:
                            log.write("INFO:Try to download: {}\n".format(ftp_path))
                            for attempt in range(10):

                                try:
                                    proc = subprocess.Popen("wget -qO- {} | gzip -d > {}".format(ftp_path, genbank_filename),
                                                            shell=True)
                                    returncode = proc.wait(timeout=500)
                                    if (returncode != 0):
                                        raise Exception

                                except Exception as e:
                                    log.write("\tWARNING:error during download\n\tWARNING:next download try of {} with attempt {} and exception: {}\n".format(genbank_filename, attempt, e))
                                    if (attempt == 9):
                                        if (isfile(genbank_filename)):
                                            log.write("\tWARNING:removing file: {}\n".format(genbank_filename))
                                            remove(genbank_filename)
                                    log.write("\tWARNING:skipped download of {}\n".format(genbank_filename))
                                else:
                                    log.write("INFO:successfully downloaded file: {}\n".format(genbank_filename))
                                    genbank_filelist.append(genbank_filename)
                                    break
                    log.write("DONE\n")
            except Exception as e:
                log.write("ERROR: Exception: {}\n".format(e))
                raise Exception(e)

        return genbank_filelist
    except Exception as e:
        raise Exception("[-] ERROR during download of genbank_files with exception: {}".format(e))

'''write_new_genbank_file
    
    This function is executed within the associated celery task. It iterates over the sequence_id_to_ftp_path dictionary
    to retrieve the downloaded genbank files in the project associated synteny directory. Then it
    executes the extract_gene_cluster_by_one_sequence function. The sequence is the target rbh sequence of the 
    dictionary. This function writes new sliced genbank files in the query sequence folder within the project folder.
    
    :param sequence_id_to_ftp_path - return from extract_assembly_ftp_paths_from_reciprocal_result_entries
        :type dict
    :param data_path - path to genbank assembly files
        :type str
    :param limit - sequences downstream and upstream to slice from genbank file
        :type int
    :param query_sequence - used to build file and directory paths
        :type str 
'''
def write_new_genbank_file(sequence_id_to_ftp_path:dict, data_path:str, limit:int, query_sequence:str, project_id:int)->dict:
    try:
        logfile = BLAST_PROJECT_DIR + str(project_id) + '/log/' + "genbank_file_writing.log"
        with open(logfile, 'w') as log:
            log.write("INFO:starting to parse genbank files\n")
            for sequence in sequence_id_to_ftp_path.keys():
                for ftp_path in sequence_id_to_ftp_path[sequence]:
                    output_file = BLAST_PROJECT_DIR + str(project_id) + '/' + query_sequence + '/' + ftp_path.split("/")[-1].split(".gz")[0] + '_sliced_gb_file.gbk'
                    genbank_file = data_path + '/' + ftp_path.split("/")[-1].split(".gz")[0]
                    log.write("INFO:trying to read genbank file at: {}\nINFO:write new genbank file into: {}\n"
                              .format(genbank_file, output_file))
                    if isfile(genbank_file) == True and isfile(output_file) == False:
                        retcode = extract_gene_cluster_by_one_sequence(sequence, limit, genbank_file, output_file, project_id)
                        if retcode != 0:
                            raise Exception("[-] ERROR during extraction of gene clusters retcode: {}".format(retcode))
                    else:
                        log.write("WARNING:there is no genbank file for {}\n".format(output_file))
        return 0
    except Exception as e:
        raise Exception("[-] ERROR during creation of sliced genbank files with exception: {}".format(e))

'''delete_sliced_genbank_files
    
    This function deletes all previously sliced genbank files and the result standalone HTML file 
    to create a new synteny plot with clinker. 
    
    :param project_id
        :type int
    :param query_sequence
        :type str
    
    :returns returncode - 1 FAILURE, 0 SUCCESS
        :type int
'''
def delete_sliced_genbank_files(project_id:int, query_sequence:str)->int:
    try:
        path_to_query_sequence = BLAST_PROJECT_DIR + str(project_id) + '/' + query_sequence +'/'
        if isdir(path_to_query_sequence) == True:
            files = listdir(path_to_query_sequence)
            for file in files:
                if file.endswith('.gbk'):
                    file = path_to_query_sequence + file
                    remove(file)
                elif file == "clinker_result_plot.html":
                    file = path_to_query_sequence + file
                    remove(file)
        else:
            return 1
        return 0
    except Exception as e:
        raise Exception("[-] ERROR during deletion of sliced synteny genbank files with exception: {}".format(e))